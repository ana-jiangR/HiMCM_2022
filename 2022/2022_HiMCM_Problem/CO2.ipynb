{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# 已有数据\n",
    "df = pd.read_excel('2022_HiMCM_Data-B-co2.xlsx',sheet_name=\"origin\")\n",
    "year = df['Year'].tolist()\n",
    "ppm = df['PPM'].tolist()\n",
    "\n",
    "# 数据处理\n",
    "# sklearn 拟合输入输出一般都是二维数组，这里将一维转换为二维。\n",
    "year = np.array(year).reshape(-1, 1)\n",
    "ppm = np.array(ppm).reshape(-1, 1)\n",
    "\n",
    "# 拟合\n",
    "reg = LinearRegression()\n",
    "reg.fit(year, ppm) #最小二乘法\n",
    "\n",
    "# 可视化\n",
    "prediction = reg.predict(year)                # 根据高度，按照拟合的曲线预测\n",
    "plt.figure('PPM~Year', figsize=(20,8))\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('PPM')\n",
    "plt.scatter(year, ppm, c='black')\n",
    "plt.plot(year, prediction, c='red')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "a = reg.coef_[0][0]     # 系数\n",
    "b = reg.intercept_[0]   # 截距\n",
    "print('Fitted equation：Y = %.6fX + %.6f' % (a, b))\n",
    "# out: 拟合的方程为：Y = 1.614036X + -2854.593264\n",
    "\n",
    "R_square = r2_score(ppm, prediction) \n",
    "\n",
    "print(reg.coef_)\n",
    "print(reg.intercept_)\n",
    "print(R_square)\n",
    "\n",
    "def get_linear(year):\n",
    "    return a * year + b \n",
    "\n",
    "maxrange = 0.0\n",
    "deviation = np.empty(0,dtype=np.float64)\n",
    "\n",
    "print(\"Poly2 Prediction Results:\")\n",
    "for i in range(1959, 2022):\n",
    "    pdict = get_linear(i)\n",
    "    dd = pdict - ppm[i-1959]  #difference\n",
    "    deviation = np.append(deviation, dd)\n",
    "\n",
    "# _____________________________________________________________________________________________\n",
    "\n",
    "avg = np.average(deviation)\n",
    "std = np.std(deviation, ddof=1)\n",
    "print(\"avg = %.10f, std = %.10f\" %(avg, std))\n",
    "\n",
    "ystart = 1959\n",
    "yend_true_data = 2021\n",
    "yend = 2201\n",
    "\n",
    "year = np.linspace(ystart, yend-1,yend - ystart )\n",
    "\n",
    "pdict = np.empty(0,dtype=np.float64)\n",
    "pdict_scatter = np.empty(0,dtype=np.float64)\n",
    "\n",
    "\n",
    "for y in range(ystart, yend):\n",
    "    predict = get_linear(y)\n",
    "    pdict = np.append(pdict, predict)\n",
    "\n",
    "    if y <= yend_true_data:\n",
    "        # use the real/true numbers.\n",
    "        pdict_scatter = np.append(pdict_scatter, ppm[y-ystart])\n",
    "        \n",
    "    else :\n",
    "        randft = np.random.normal(avg, std)\n",
    "        pdict_scatter = np.append(pdict_scatter, predict + randft)\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_traces(go.Scatter(x=year[:yend_true_data-ystart+1], y=pdict_scatter[:yend_true_data-ystart+1], mode = \"markers\", name = \"true data before 2021\"))\n",
    "fig.add_traces(go.Scatter(x=year[yend_true_data-ystart+1:], y=pdict_scatter[yend_true_data-ystart+1:], mode = \"markers\", name = \"predict data after 2021\"))\n",
    "fig.add_traces(go.Scatter(x=year, y=pdict, name = \"trendline\"))\n",
    "\n",
    "fig.update_layout( \n",
    "        xaxis = dict(\n",
    "            title = \"Year\"\n",
    "        ),\n",
    "        yaxis = dict(\n",
    "            title = \"PPM\"\n",
    "        ),\n",
    "        title='PPM Increment with Years',\n",
    "        title_x=0.5,\n",
    "        # autosize=False,\n",
    "        width=2000,\n",
    "        height=1000,\n",
    "    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 数据处理\n",
    "# sklearn 拟合输入输出一般都是二维数组，这里将一维转换为二维。\n",
    "year = np.array(year).reshape(-1, 1)\n",
    "ppm = np.array(ppm).reshape(-1, 1)\n",
    "\n",
    "# 拟合\n",
    "reg = LinearRegression()\n",
    "reg.fit(year, ppm) #最小二乘法\n",
    "\n",
    "# 可视化\n",
    "prediction = reg.predict(year)                # 根据高度，按照拟合的曲线预测\n",
    "plt.figure('PPM~Year', figsize=(20,8))\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('PPM')\n",
    "plt.scatter(year, ppm, c='black')\n",
    "plt.plot(year, prediction, c='red')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "a = reg.coef_[0][0]     # 系数\n",
    "b = reg.intercept_[0]   # 截距\n",
    "print('拟合的方程为：Y = %.6fX + %.6f' % (a, b))\n",
    "# out: 拟合的方程为：Y = 1.614036X + -2854.593264\n",
    "\n",
    "R_square = r2_score(ppm, prediction) \n",
    "\n",
    "print(reg.coef_)\n",
    "print(reg.intercept_)\n",
    "print(R_square)\n",
    "\n",
    "def get_linear(year):\n",
    "    return a * year + b \n",
    "\n",
    "maxrange = 0.0\n",
    "deviation = np.empty(0,dtype=np.float64)\n",
    "\n",
    "print(\"Poly2 Prediction Results:\")\n",
    "for i in range(1959, 2022):\n",
    "    pdict = get_linear(i)\n",
    "    dd = pdict - ppm[i-1959]  #difference\n",
    "    deviation = np.append(deviation, dd)\n",
    "\n",
    "# _____________________________________________________________________________________________\n",
    "\n",
    "avg = np.average(deviation)\n",
    "std = np.std(deviation, ddof=1)\n",
    "print(\"avg = %.10f, std = %.10f\" %(avg, std))\n",
    "\n",
    "ystart = 1959\n",
    "yend_true_data = 2021\n",
    "yend = 2101\n",
    "\n",
    "year = np.linspace(ystart, yend-1,yend - ystart )\n",
    "\n",
    "pdict = np.empty(0,dtype=np.float64)\n",
    "pdict_scatter = np.empty(0,dtype=np.float64)\n",
    "\n",
    "\n",
    "for y in range(ystart, yend):\n",
    "    predict = get_linear(y)\n",
    "    pdict = np.append(pdict, predict)\n",
    "\n",
    "    if y <= yend_true_data:\n",
    "        # use the real/true numbers.\n",
    "        pdict_scatter = np.append(pdict_scatter, ppm[y-ystart])\n",
    "        \n",
    "    else :\n",
    "        randft = np.random.normal(avg, std)\n",
    "        pdict_scatter = np.append(pdict_scatter, predict + randft)\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_traces(go.Scatter(x=year[:yend_true_data-ystart+1], y=pdict_scatter[:yend_true_data-ystart+1], mode = \"markers\", name = \"true data before 2021\"))\n",
    "fig.add_traces(go.Scatter(x=year[yend_true_data-ystart+1:], y=pdict_scatter[yend_true_data-ystart+1:], mode = \"markers\", name = \"predict data after 2021\"))\n",
    "fig.add_traces(go.Scatter(x=year, y=pdict, name = \"trendline\"))\n",
    "\n",
    "fig.update_layout( \n",
    "        xaxis = dict(\n",
    "            title = \"Year\"\n",
    "        ),\n",
    "        yaxis = dict(\n",
    "            title = \"PPM\"\n",
    "        ),\n",
    "        title='PPM Increment with Years',\n",
    "        title_x=0.5,\n",
    "        # autosize=False,\n",
    "        width=2000,\n",
    "        height=1000,\n",
    "    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# # 可视化\n",
    "# prediction = reg.predict(year)                # 根据高度，按照拟合的曲线预测\n",
    "# plt.figure('PPM~Year', figsize=(20,8))\n",
    "# plt.xlabel('Year')\n",
    "# plt.ylabel('PPM')\n",
    "# plt.scatter(year, ppm, c='black')\n",
    "# plt.plot(year, prediction, c='red')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# a = reg.coef_[0][0]     # 系数\n",
    "# b = reg.intercept_[0]   # 截距\n",
    "# print('拟合的方程为：Y = %.6fX + %.6f' % (a, b))\n",
    "# # out: 拟合的方程为：Y = 1.614036X + -2854.593264\n",
    "\n",
    "\n",
    "# R_square = r2_score(ppm, prediction) \n",
    "\n",
    "# print(reg.coef_)\n",
    "# print(reg.intercept_)\n",
    "# print(R_square)\n",
    "\n",
    "\n",
    "\n",
    "# def get_linear(year):\n",
    "#     return a * year + b \n",
    "\n",
    "# print(\"Linear Prediction Results:\")\n",
    "# # for i in range(2021, 2101):\n",
    "# #     print('Year-%d : %.2f' % (i, get_linear(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reg.fit(year, ppm) #最小二乘法\n",
    "\n",
    "\n",
    "\n",
    "# # 可视化\n",
    "# prediction = reg.predict(year)                # 根据高度，按照拟合的曲线预测\n",
    "# plt.figure('PPM~Year', figsize=(20,8))\n",
    "# plt.xlabel('Year')\n",
    "# plt.ylabel('PPM')\n",
    "# plt.scatter(year, ppm, c='black')\n",
    "# plt.plot(year, prediction, c='red')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# a = reg.coef_[0][0]     # 系数\n",
    "# b = reg.intercept_[0]   # 截距\n",
    "# print('拟合的方程为：Y = %.6fX + %.6f' % (a, b))\n",
    "# # out: 拟合的方程为：Y = 1.614036X + -2854.593264\n",
    "\n",
    "\n",
    "# R_square = r2_score(ppm, prediction) \n",
    "\n",
    "# print(reg.coef_)\n",
    "# print(reg.intercept_)\n",
    "# print(R_square)\n",
    "\n",
    "\n",
    "\n",
    "# def get_linear(year):\n",
    "#     return a * year + b \n",
    "\n",
    "# print(\"Linear Prediction Results:\")\n",
    "# # for i in range(2021, 2101):\n",
    "# #     print('Year-%d : %.2f' % (i, get_linear(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code source: Jaques Grobler\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 已有数据\n",
    "df = pd.read_excel('2022_HiMCM_Data-B-co2.xlsx',sheet_name=\"origin\")\n",
    "year = df['Year'].to_numpy()\n",
    "ppm = df['PPM'].to_numpy()\n",
    "\n",
    "# print(year)\n",
    "# Load the  dataset\n",
    "# diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True)\n",
    "# print(diabetes_X)\n",
    "\n",
    "diabetes_X = year\n",
    "diabetes_y = ppm\n",
    "\n",
    "# Use only one feature\n",
    "# diabetes_X = diabetes_X[:, np.newaxis, 2]\n",
    "# print(diabetes_X)\n",
    "\n",
    "diabetes_X = np.array(diabetes_X).reshape(-1, 1)\n",
    "diabetes_y = np.array(diabetes_y).reshape(-1, 1)\n",
    "\n",
    "# Split the data into training/testing sets\n",
    "diabetes_X_train = diabetes_X[:-50]\n",
    "diabetes_X_test = diabetes_X[-50:]\n",
    "\n",
    "# Split the targets into training/testing sets\n",
    "diabetes_y_train = diabetes_y[:-50]\n",
    "diabetes_y_test = diabetes_y[-50:]\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(diabetes_X_train, diabetes_y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "diabetes_y_pred = regr.predict(diabetes_X_test)\n",
    "\n",
    "# The coefficients\n",
    "print(\"Coefficients: \\n\", regr.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(diabetes_y_test, diabetes_y_pred))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print(\"Coefficient of determination: %.2f\" % r2_score(diabetes_y_test, diabetes_y_pred))\n",
    "\n",
    "# Plot outputs\n",
    "plt.scatter(diabetes_X_test, diabetes_y_test, color=\"black\")\n",
    "plt.plot(diabetes_X_test, diabetes_y_pred, color=\"blue\")\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所需的模块\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 已有数据\n",
    "height = [0.0, 500.0, 1000.0, 1500.0, 2000.0, 2500.0, 3000.0, 3500.0, 4000.0]\n",
    "temp = [12.834044009405147, 10.190648986884316, 5.50022874963469, 2.8546651452636795, -0.7064882183657739, -4.065322810462405, -7.1274795772446575, -10.058878545913904, -13.206465051538661]\n",
    "\n",
    "\n",
    "# 数据处理\n",
    "# sklearn 拟合输入输出一般都是二维数组，这里将一维转换为二维。\n",
    "height = np.array(height).reshape(-1, 1)\n",
    "temp = np.array(temp).reshape(-1, 1)\n",
    "\n",
    "# 拟合\n",
    "reg = LinearRegression()\n",
    "reg.fit(height, temp)\n",
    "a = reg.coef_[0][0]     # 系数\n",
    "b = reg.intercept_[0]   # 截距\n",
    "print('拟合的方程为：Y = %.6fX + %.6f' % (a, b))\n",
    "# out: 拟合的方程为：Y = -0.006570X + 12.718507\n",
    "\n",
    "# 可视化\n",
    "prediction = reg.predict(height)                # 根据高度，按照拟合的曲线预测温度值\n",
    "plt.figure('海拔高度~温度关系曲线拟合结果', figsize=(12,8))\n",
    "plt.rcParams['font.family'] = ['sans-serif']    # 设置matplotlib 显示中文\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']    # 设置matplotlib 显示中文\n",
    "plt.xlabel('高度')\n",
    "plt.ylabel('温度')\n",
    "plt.scatter(height,temp,  c='black')\n",
    "plt.plot(height, prediction, c='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quadratic\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "plt.figure('PPM~Year', figsize=(20,8))\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('PPM')\n",
    "\n",
    "\n",
    "# 已有数据\n",
    "df = pd.read_excel('2022_HiMCM_Data-B-co2.xlsx',sheet_name=\"origin\")\n",
    "year = df['Year'].tolist()\n",
    "ppm = df['PPM'].tolist()\n",
    "plt.scatter(year, ppm, c=\"black\")\n",
    "\n",
    "\n",
    "# f(x) = 2x^2 + 1x + 1\n",
    "# f = np.poly1d([2,1,1])\n",
    "# y = f(x)\n",
    "\n",
    "# 2D\n",
    "year = np.reshape(year, (-1,1))\n",
    "\n",
    "\n",
    "# 2 次多项式\n",
    "ploy_reg = PolynomialFeatures(degree=2)\n",
    "year_ploy = ploy_reg.fit_transform(year)\n",
    "\n",
    "lin_reg=LinearRegression()\n",
    "lin_reg.fit(year_ploy,ppm)\n",
    "\n",
    "ppm_pred = lin_reg.predict(year_ploy)\n",
    "\n",
    "\n",
    "plt.plot(year, ppm_pred, c=\"red\")\n",
    "plt.show()\n",
    "\n",
    "print(lin_reg.coef_)\n",
    "\n",
    "a = lin_reg.coef_[0]\n",
    "b = lin_reg.coef_[1]\n",
    "c = lin_reg.coef_[2]\n",
    "d = lin_reg.intercept_\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(d)\n",
    "\n",
    "def get_poly2(year):\n",
    "    return lin_reg.coef_[2] * year * year + lin_reg.coef_[1] * year + lin_reg.intercept_\n",
    "\n",
    "print(\"Poly2 Prediction Results:\")\n",
    "for i in range(1959, 2022):\n",
    "    pdict = get_poly2(i)\n",
    "    dd = pdict - ppm[i-1959]  #difference\n",
    "    # print('Year-%d : %.2f -> %.2f' % (i, pdict, dd))\n",
    "\n",
    "\n",
    "for i in range(2022, 2101):\n",
    "    pdict = get_poly2(i)\n",
    "    print('Year-%d : %.2f' % (i, pdict))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quadratic\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "plt.figure('PPM~Year', figsize=(20,8))\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('PPM')\n",
    "\n",
    "# 已有数据\n",
    "df = pd.read_excel('2022_HiMCM_Data-B-co2.xlsx',sheet_name=\"origin\")\n",
    "year = df['Year'].tolist()\n",
    "ppm = df['PPM'].tolist()\n",
    "\n",
    "plt.scatter(year, ppm, c=\"black\")\n",
    "\n",
    "coef = np.polyfit(year, ppm, 2)\n",
    "ppm_fit= np.polyval(coef, year)\n",
    "\n",
    "plt.plot(year, ppm_fit, c=\"red\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# y = ax^2 + bx + c\n",
    "a = coef[0]\n",
    "b = coef[1]\n",
    "c = coef[2]\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "\n",
    "def get_poly2(year):\n",
    "    return a * year * year + b * year + c\n",
    "\n",
    "print(\"Poly2 Prediction Results:\")\n",
    "for i in range(1959, 2022):\n",
    "    pdict = get_poly2(i)\n",
    "    dd = pdict - ppm[i-1959]  #difference\n",
    "    # print('Year-%d : %.2f -> %.2f' % (i, pdict, dd))\n",
    "\n",
    "\n",
    "for i in range(2022, 2101):\n",
    "    pdict = get_poly2(i)\n",
    "    print('Year-%d : %.2f' % (i, pdict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure('PPM~Year', figsize=(20,8))\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('PPM')\n",
    "\n",
    "# 已有数据\n",
    "df = pd.read_excel('2022_HiMCM_Data-B-co2.xlsx',sheet_name=\"origin\")\n",
    "year = df['Year'].tolist()\n",
    "degree = df['Degree'].tolist()\n",
    "\n",
    "plt.scatter(year, degree, c=\"black\")\n",
    "\n",
    "\n",
    "\n",
    "coef = np.polyfit(year, degree, 2)\n",
    "ppm_fit= np.polyval(coef, year)\n",
    "\n",
    "plt.plot(year, ppm_fit, c=\"red\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "print(len(year))\n",
    "\n",
    "# y = ax^2 + bx + c\n",
    "a = coef[0]\n",
    "b = coef[1]\n",
    "c = coef[2]\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "\n",
    "def get_poly2(year):\n",
    "    return a * year * year + b * year + c\n",
    "\n",
    "\n",
    "maxrange = 0.0\n",
    "\n",
    "print(\"Poly2 Prediction Results:\")\n",
    "for i in range(1959, 2022):\n",
    "    pdict = get_poly2(i)\n",
    "    dd = pdict - degree[i-1959]  #difference\n",
    "    if np.abs(dd) - maxrange > 0.001 :\n",
    "        maxrange = np.abs(dd) \n",
    "    # print('Year-%d : %.2f -> %.2f' % (i, pdict, dd))\n",
    "\n",
    "maxrange = maxrange * 1.2\n",
    "print(\"fit max deviation: %.3f\" % (maxrange))\n",
    "\n",
    "\n",
    "for i in range(2022, 2101):\n",
    "    randft = np.random.default_rng().uniform(low=-1*maxrange, high=maxrange)\n",
    "    pdict = get_poly2(i) + randft\n",
    "    # print('Year-%d : %.2f' % (i, pdict))\n",
    "\n",
    "plt.figure('PPM~Year', figsize=(25,13))\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('PPM')\n",
    "\n",
    "ystart = 1959\n",
    "yend_true_data = 2021\n",
    "yend = 2101\n",
    "\n",
    "year = np.linspace(ystart, yend-1,yend - ystart )\n",
    "\n",
    "\n",
    "pdict = np.empty(0,dtype=np.float64)\n",
    "pdict_scatter = np.empty(0,dtype=np.float64)\n",
    "\n",
    "\n",
    "for y in range(ystart, yend):\n",
    "    predict = get_poly2(y)\n",
    "    pdict = np.append(pdict, predict)\n",
    "\n",
    "    if y <= yend_true_data:\n",
    "        # use the real/true numbers.\n",
    "        pdict_scatter = np.append(pdict_scatter, degree[y-ystart])\n",
    "        \n",
    "    else :\n",
    "        randft = np.random.default_rng().uniform(low=-1*maxrange, high=maxrange)\n",
    "        pdict_scatter = np.append(pdict_scatter, predict + randft)\n",
    "\n",
    "print(year.shape)\n",
    "print(pdict_scatter.shape)\n",
    "print(pdict.shape)\n",
    "\n",
    "\n",
    "plt.scatter(year, pdict_scatter, c=\"black\")\n",
    "plt.plot(year, pdict, c=\"red\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Temperature & 正态分布 & predict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import r2_score \n",
    "\n",
    "\n",
    "\n",
    "# 已有数据\n",
    "df = pd.read_excel('2022_HiMCM_Data-B-co2.xlsx',sheet_name=\"origin\")\n",
    "year = df['Year'].tolist()\n",
    "degree = df['Degree'].tolist()\n",
    "\n",
    "# 2次\n",
    "coef = np.polyfit(year, degree, 2)\n",
    "degree_fit= np.polyval(coef, year)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_traces(go.Scatter(x=year, y=degree, mode = \"markers\", name = \"real data\"))\n",
    "fig.add_traces(go.Scatter(x=year, y=degree_fit, mode = \"lines\", name = \"trendline\"))\n",
    "fig.update_layout( \n",
    "        title='Degree Increment with Years',\n",
    "        title_x=0.5,\n",
    "        # autosize=False,\n",
    "        width=1500,\n",
    "        height=700,\n",
    "    )\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "R_square = r2_score(degree, degree_fit) \n",
    "print('Coefficient of Determination (R^2): ', R_square) \n",
    "\n",
    "# print(len(year))\n",
    "\n",
    "# y = ax^2 + bx + c\n",
    "a = coef[0]\n",
    "b = coef[1]\n",
    "c = coef[2]\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "\n",
    "def get_poly2(year):\n",
    "    return a * year * year + b * year + c\n",
    "\n",
    "deviation = np.empty(0,dtype=np.float64)\n",
    "\n",
    "print(\"Poly2 Prediction Results:\")\n",
    "for i in range(1959, 2022):\n",
    "    pdict = get_poly2(i)\n",
    "    dd = pdict - degree[i-1959]  #difference\n",
    "    deviation = np.append(deviation, dd)\n",
    "\n",
    "go.Figure(data=[go.Histogram(x=deviation)]).show()\n",
    "\n",
    "avg = np.average(deviation)\n",
    "std = np.std(deviation, ddof=1)\n",
    "print(\"avg = %.10f, std = %.10f\" %(avg, std))\n",
    "\n",
    "# for i in range(2022, 2101):\n",
    "#     randft = np.random.normal(avg, std)\n",
    "#     pdict = get_poly2(i) + randft\n",
    "#     # print('Year-%d : %.2f' % (i, pdict))\n",
    "\n",
    "\n",
    "ystart = 1959\n",
    "yend_true_data = 2021\n",
    "yend = 2201\n",
    "\n",
    "year = np.linspace(ystart, yend-1,yend - ystart )\n",
    "\n",
    "pdict = np.empty(0,dtype=np.float64)\n",
    "pdict_scatter = np.empty(0,dtype=np.float64)\n",
    "\n",
    "\n",
    "for y in range(ystart, yend):\n",
    "    predict = get_poly2(y)\n",
    "    pdict = np.append(pdict, predict)\n",
    "\n",
    "    if y <= yend_true_data:\n",
    "        # use the real/true numbers\n",
    "        pdict_scatter = np.append(pdict_scatter, degree[y-ystart])\n",
    "    else:\n",
    "        randft = np.random.normal(avg, std)\n",
    "        pdict_scatter = np.append(pdict_scatter, predict + randft)\n",
    "\n",
    "\n",
    "\n",
    "# fig.add_traces(go.Scatter(x=year, y=pdict_scatter, mode = \"markers\", name = \"data (before/after 2021)\"))\n",
    "fig = go.Figure()\n",
    "\n",
    "# fig.add_traces(go.Scatter(x=year[:yend_true_data-ystart+1], y=pdict_scatter[:yend_true_data-ystart+1], mode = \"markers\", name = \"true data before 2021\"))\n",
    "# fig.add_traces(go.Scatter(x=year[yend_true_data-ystart+1:], y=pdict_scatter[yend_true_data-ystart+1:], mode = \"markers\", name = \"predict data after 2021\"))\n",
    "\n",
    "fig.add_traces(go.Bar(x=year[:yend_true_data-ystart+1], y=pdict_scatter[:yend_true_data-ystart+1], name = \"true data before 2021\"))\n",
    "fig.add_traces(go.Bar(x=year[yend_true_data-ystart+1:], y=pdict_scatter[yend_true_data-ystart+1:], name = \"predict data after 2021\"))\n",
    "\n",
    "\n",
    "fig.add_traces(go.Scatter(x=year, y=pdict, mode = \"lines\", name = \"trendline\"))\n",
    "\n",
    "fig.update_layout(\n",
    "        xaxis = dict(\n",
    "            title = \"Year\"\n",
    "        ),\n",
    "        yaxis = dict(\n",
    "            title = \"Degree(Celcius)\"\n",
    "        ),\n",
    "        title='Degree Increment with Years',\n",
    "        title_x=0.5,\n",
    "        # autosize=False,\n",
    "        width=2500,\n",
    "        height=1000,\n",
    "    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quadratic 正态分布&predict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import r2_score \n",
    "\n",
    "# 已有数据\n",
    "df = pd.read_excel('2022_HiMCM_Data-B-co2.xlsx',sheet_name=\"origin\")\n",
    "year = df['Year'].tolist()\n",
    "ppm = df['PPM'].tolist()\n",
    "\n",
    "coef = np.polyfit(year, ppm, 2) #- numpy polyfit\n",
    "ppm_fit= np.polyval(coef, year)\n",
    "\n",
    "R_square = r2_score(ppm, ppm_fit) \n",
    "print('Coefficient of Determination (R^2): ', R_square) \n",
    "\n",
    "print(len(year))\n",
    "\n",
    "# y = ax^2 + bx + c\n",
    "a = coef[0]\n",
    "b = coef[1]\n",
    "c = coef[2]\n",
    "\n",
    "print(\"y = %.3f * X^2 + %.3f * X + %.3f\" % (a, b, c))\n",
    "\n",
    "\n",
    "def get_poly2(year):\n",
    "    return a * year * year + b * year + c\n",
    "\n",
    "\n",
    "# maxrange = 0.0\n",
    "deviation = np.empty(0,dtype=np.float64)\n",
    "\n",
    "print(\"Poly2 Prediction Results:\")\n",
    "for i in range(1959, 2022):\n",
    "    pdict = get_poly2(i)\n",
    "    dd = pdict - ppm[i-1959]  #difference\n",
    "    deviation = np.append(deviation, dd)\n",
    "    # print('Year-%d : %.2f -> %.2f' % (i, pdict, dd))\n",
    "\n",
    "# print(deviation)\n",
    "go.Figure(data=[go.Histogram(x=deviation)]).show()\n",
    "\n",
    "# _____________________________________________________________________________________________\n",
    "\n",
    "\n",
    "avg = np.average(deviation)\n",
    "std = np.std(deviation, ddof=1)\n",
    "print(\"avg = %.10f, std = %.10f\" %(avg, std))\n",
    "\n",
    "ystart = 1959\n",
    "yend_true_data = 2021\n",
    "yend = 2101\n",
    "\n",
    "year = np.linspace(ystart, yend-1,yend - ystart )\n",
    "\n",
    "pdict = np.empty(0,dtype=np.float64)\n",
    "pdict_scatter = np.empty(0,dtype=np.float64)\n",
    "\n",
    "\n",
    "for y in range(ystart, yend):\n",
    "    predict = get_poly2(y)\n",
    "    pdict = np.append(pdict, predict)\n",
    "\n",
    "    if y <= yend_true_data:\n",
    "        # use the real/true numbers.\n",
    "        pdict_scatter = np.append(pdict_scatter, ppm[y-ystart])\n",
    "        \n",
    "    else :\n",
    "        randft = np.random.normal(avg, std)\n",
    "        pdict_scatter = np.append(pdict_scatter, predict + randft)\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_traces(go.Scatter(x=year[:yend_true_data-ystart+1], y=pdict_scatter[:yend_true_data-ystart+1], mode = \"markers\", name = \"true data before 2021\"))\n",
    "fig.add_traces(go.Scatter(x=year[yend_true_data-ystart+1:], y=pdict_scatter[yend_true_data-ystart+1:], mode = \"markers\", name = \"predict data after 2021\"))\n",
    "fig.add_traces(go.Scatter(x=year, y=pdict, name = \"trendline\"))\n",
    "\n",
    "fig.update_layout( \n",
    "        xaxis = dict(\n",
    "            title = \"Year\"\n",
    "        ),\n",
    "        yaxis = dict(\n",
    "            title = \"PPM\"\n",
    "        ),\n",
    "        title='PPM Increment with Years',\n",
    "        title_x=0.5,\n",
    "        # autosize=False,\n",
    "        width=2500,\n",
    "        height=1000,\n",
    "    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "# 已有数据linear和quadratic\n",
    "df = pd.read_excel('2022_HiMCM_Data-B-co2.xlsx', sheet_name=\"origin\")\n",
    "year = df['Year'].tolist()\n",
    "ppm = df['PPM'].tolist()\n",
    "\n",
    "\n",
    "fig = px.scatter(df, x=\"PPM\", y=\"Degree\", trendline=\"ols\",\n",
    "                 # log_x=True,\n",
    "                 # trendline_options=dict(log_x=True)\n",
    "                 )\n",
    "\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n",
    "fig = px.scatter(df, x=\"Year\", y=\"Degree\", trendline=\"lowess\",\n",
    "                 # log_x=True,\n",
    "                 # trendline_options=dict(log_x=True)\n",
    "                 )\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#相关性\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 已有数据\n",
    "df = pd.read_excel('2022_HiMCM_Data-B-co2.xlsx',sheet_name=\"origin\")\n",
    "year = df['Year']\n",
    "ppm = df['PPM']\n",
    "degree = df['Degree']\n",
    "\n",
    "rpd = np.corrcoef(ppm, degree)\n",
    "print(rpd[0][1])\n",
    "\n",
    "cp = degree.corr(ppm, method='pearson')  # default - explain why\n",
    "print(cp)\n",
    "\n",
    "print(df.corr())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#基于logistic模型人口预测\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd\n",
    " \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def logistic_increase_function(t,K,P0,r):\n",
    "    # '''\n",
    "    # t ,list,日期序列,[11,18,19,20 ,21, 22, 23, 24,  25,  26,  27]\n",
    "    # t0,int,日期首日\n",
    "    # r,float,r为增长速率，r越大则增长越快，越快逼近K值 - 越陡峭;r越小增长越慢，越慢逼近K值。\n",
    "    # P0为初始容量，就是t=0时刻的数量\n",
    "    # K,float,K为环境容量，即增长到最后，P(t)能达到的极限,一般为1\n",
    "    \n",
    "    # '''\n",
    "    t0=1900  # 第一天\n",
    "    r=0.6\n",
    "    #   r = 0.55\n",
    "    # t:time   t0:initial time    P0:initial_value    K:capacity  r:increase_rate\n",
    "    exp_value=np.exp(r*(t-t0))\n",
    "    return (K*exp_value*P0)/(K+(exp_value-1)*P0)\n",
    " \n",
    "# '''\n",
    "# 1.11日41例\n",
    "# 1.18日45例\n",
    "# 1.19日62例\n",
    "# 1.20日291例\n",
    "# 1.21日440例\n",
    "# 1.22日571例\n",
    "# 1.23日830例\n",
    "# 1.24日1287例\n",
    "# 1.25日1975例\n",
    "# 1.26日2744例\n",
    "# 1.27日4515例\n",
    "# '''\n",
    "\n",
    "# 已有数据\n",
    "df = pd.read_excel('population_world.xlsx',sheet_name=\"Sheet1\")\n",
    "year = df['Year'].tolist()\n",
    "popu = df['Population'].tolist()\n",
    "\n",
    "\n",
    "# 数据处理\n",
    "# sklearn 拟合输入输出一般都是二维数组，这里将一维转换为二维。\n",
    "# year = np.array(year).reshape(-1, 1)\n",
    "# popu = np.array(popu).reshape(-1, 1)\n",
    "\n",
    "# #  日期及感染人数\n",
    "# t=[11,18,19,20 ,21, 22, 23, 24,  25,  26,  27]\n",
    "year=np.array(year)\n",
    "# P=[41,45,62,291,440,571,830,1287,1975,2744,4515]\n",
    "popu=np.array(popu)\n",
    " \n",
    "# 用最小二乘法估计拟合\n",
    "popt, pcov = curve_fit(logistic_increase_function, year, popu)\n",
    "# popt - K，P0，r\n",
    "# 最终K=4.01665705e+10人会被感染\n",
    "# array([7.86278276e+03, 2.96673434e-01, 1.00000000e+00])\n",
    "\n",
    "#获取popt里面是拟合系数\n",
    "print(\"K:capacity  P0:initial_value   r:increase_rate   t:time\")\n",
    "print(popt)\n",
    "\n",
    "\n",
    "#拟合后预测的P值\n",
    "P_predict = logistic_increase_function(year,popt[0],popt[1],popt[2])\n",
    "\n",
    "\n",
    "#未来预测\n",
    "future=[2022,2023,2024,2025,2026,2027,2028,2029,2030,2031,2032,2033,2034,2035,2036,2037,2038,2039,2040]\n",
    "future=np.array(future)\n",
    "future_predict=logistic_increase_function(future,popt[0],popt[1],popt[2])\n",
    "\n",
    "\n",
    "#近期情况预测\n",
    "# tomorrow=[28,29,30,32,33,35,37,40]\n",
    "# tomorrow=np.array(tomorrow)\n",
    "# tomorrow_predict=logistic_increase_function(tomorrow,popt[0],popt[1],popt[2])\n",
    " \n",
    "#绘图\n",
    "plot1 = plt.plot(year, popu, 's',label=\"confimed\")\n",
    "plot2 = plt.plot(year, P_predict, 'r',label='predict')\n",
    "# plot3 = plt.plot(tomorrow, tomorrow_predict, 's',label='predict infected people number')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('population')\n",
    " \n",
    "plt.legend(loc=0) #指定legend的位置右下角\n",
    " \n",
    "print(logistic_increase_function(np.array(100),popt[0],popt[1],popt[2]))\n",
    "# print(logistic_increase_function(np.array(101),popt[0],popt[1],popt[2]))\n",
    "print(future_predict)\n",
    "\n",
    "plt.show()\n",
    " \n",
    " \n",
    "#未来预测绘图\n",
    "#plot2 = plt.plot(t, P_predict, 'r',label='polyfit values')\n",
    "#plot3 = plt.plot(future, future_predict, 'r',label='polyfit values')\n",
    "#plt.show()\n",
    " \n",
    " \n",
    "print(\"Program done!\")\n",
    "\n",
    "\n",
    "# # # '''\n",
    "# # # # 拟合年龄\n",
    "# # # '''\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# #定义x、y散点坐标\n",
    "# x = [2000,2010,2020,2030,2040]\n",
    "# x = np.array(x)\n",
    "# print('x is :\\n',x)\n",
    "# num = [174,236,305,334,349,351,342,323]\n",
    "# y = np.array(num)\n",
    "# print('y is :\\n',y)\n",
    "# #用3次多项式拟合\n",
    "# f1 = np.polyfit(x, y, 3)\n",
    "# print('f1 is :\\n',f1)\n",
    "\n",
    "# p1 = np.poly1d(f1)\n",
    "# print('p1 is :\\n',p1)\n",
    "\n",
    "# #也可使用yvals=np.polyval(f1, x)\n",
    "\n",
    "# yvals = p1(x)\n",
    "# print('yvals is :\\n',yvals)\n",
    "\n",
    "\n",
    "# #绘图\n",
    "# plot1 = plt.plot(x, y, 's',label='original values')\n",
    "# plot2 = plt.plot(x, yvals, 'r',label='polyfit values')\n",
    "# plt.xlabel('x')\n",
    "# plt.ylabel('y')\n",
    "# plt.legend(loc=4) #指定legend的位置右下角\n",
    "# plt.title('polyfitting')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r2_score\n",
    "import numpy\n",
    "actual = [1,2,3,4,5]\n",
    "predict = [1,2.5,3,4.9,4.9]\n",
    " \n",
    "corr_matrix = numpy.corrcoef(actual, predict)\n",
    "corr = corr_matrix[0,1]\n",
    "R_sq = corr**2\n",
    " \n",
    "print(R_sq)\n",
    "\n",
    "\n",
    "from sklearn.metrics import r2_score \n",
    "\n",
    "R_square = r2_score(actual, predict) \n",
    "print('Coefficient of Determination', R_square) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#随机（无正态分布)\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import r2_score \n",
    "\n",
    "df = pd.read_excel('random projection.xlsx',  sheet_name=\"orig\")\n",
    "df1 = pd.read_excel('random projection.xlsx', sheet_name=\"pred\")\n",
    "\n",
    "yearo = df['Year'].tolist()\n",
    "ppmo = df['PPM'].tolist()\n",
    "\n",
    "yeard = df1['Year'].tolist()\n",
    "ppmd = df1['PPM'].tolist()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_traces(go.Scatter(x=yearo, y=ppmo, mode = \"markers+lines\", name = \"true_data\"))\n",
    "fig.add_traces(go.Scatter(x=yeard, y=ppmd, mode = \"markers+lines\", name = \"predict_data\"))\n",
    "\n",
    "fig.update_layout( \n",
    "        xaxis = dict(\n",
    "            title = \"Year\"\n",
    "        ),\n",
    "        yaxis = dict(\n",
    "            title = \"PPM\"\n",
    "        ),\n",
    "        title='PPM Increment with Years',\n",
    "        title_x=0.5,\n",
    "        # autosize=False,\n",
    "        width=1500,\n",
    "        height=800,\n",
    "    )\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import *\n",
    "\n",
    "x, y, t, z, nu = symbols('x y t z nu')\n",
    "\n",
    "init_printing(use_unicode=True)\n",
    "\n",
    "print(diff(sin(x)*exp(x), x))\n",
    "\n",
    "integrate(exp(x)*sin(x) + exp(x)*cos(x), x)\n",
    "\n",
    "# print(integrate(exp(x)*sin(x) + exp(x)*cos(x), x))\n",
    "\n",
    "print(integrate(sin(x**2), (x, -oo, oo)))\n",
    "\n",
    "limit(sin(x)/x, x, 0)\n",
    "\n",
    "solve(x**2 - 2, x)\n",
    "\n",
    "\n",
    "# y = Function('y')\n",
    "# dsolve(Eq(y(t).diff(t, t) - y(t), exp(t)), y(t))\n",
    "\n",
    "print(expand((x + 2)*(x - 3)))\n",
    "\n",
    "factor(x**3 - x**2 + x - 1)\n",
    "\n",
    "factor_list(x**2*z + 4*x*y*z + 4*y**2*z)\n",
    "\n",
    "cancel((x**2 + 2*x + 1)/(x**2 + x))\n",
    "\n",
    "solve([x**2 - y**2/exp(x)], [x, y], dict=True)\n",
    "\n",
    "solveset(x**3 - 6*x**2 + 9*x, x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import r2_score \n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "\n",
    "\n",
    "# 已有数据\n",
    "df = pd.read_excel('2022_HiMCM_Data-B-co2.xlsx',sheet_name=\"origin\")\n",
    "year = df['Year'].to_numpy()\n",
    "ppm = df['PPM'].to_numpy()\n",
    "\n",
    "# print(year)\n",
    "# print(ppm)\n",
    "\n",
    "coef = np.polyfit(year, np.log(ppm), 1, w=np.sqrt(ppm))\n",
    "print(coef)\n",
    "\n",
    "a = np.exp(coef[1])\n",
    "b = coef[0]\n",
    "ppm_fit = a * np.exp(b * year)\n",
    "\n",
    "\n",
    "R_square = r2_score(ppm, ppm_fit) \n",
    "print('Coefficient of Determination (R^2): ', R_square) \n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_traces(go.Scatter(x=year, y=ppm, mode = \"markers\", name = \"real data\"))\n",
    "fig.add_traces(go.Scatter(x=year, y=ppm_fit, mode = \"lines\", name = \"predictline\"))\n",
    "fig.update_layout( \n",
    "        title='PPM with Years',\n",
    "        title_x=0.5,\n",
    "        # autosize=False,\n",
    "        width=1500,\n",
    "        height=700,\n",
    "    )\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ppm = a * e^ (b * year)\n",
    "print(\"y = %.3f * b^ (%.3f * year)\" % (a, b))\n",
    "\n",
    "\n",
    "def get_exp(a, b, year):\n",
    "    return a * np.exp(b * year)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "deviation = np.empty(0,dtype=np.float64)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(1959, 2022):\n",
    "    pdict = get_exp(a, b, i)\n",
    "    dd = pdict - ppm[i-1959]  #difference\n",
    "    deviation = np.append(deviation, dd)\n",
    "    # print('Year-%d : %.2f -> %.2f' % (i, pdict, dd))\n",
    "\n",
    "\n",
    "# print(deviation)\n",
    "go.Figure(data=[go.Histogram(x=deviation)]).show()\n",
    "\n",
    "# _____________________________________________________________________________________________\n",
    "\n",
    "\n",
    "avg = np.average(deviation)\n",
    "std = np.std(deviation, ddof=1)\n",
    "print(\"avg = %.10f, std = %.10f\" %(avg, std))\n",
    "# x = np.random.normal(avg, std, 10000)\n",
    "# go.Figure(data=[go.Histogram(x=x)]).show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ystart = 1959\n",
    "yend_true_data = 2021\n",
    "yend = 2101\n",
    "\n",
    "year = np.linspace(ystart, yend-1,yend - ystart )\n",
    "\n",
    "\n",
    "pdict = np.empty(0,dtype=np.float64)\n",
    "pdict_scatter = np.empty(0,dtype=np.float64)\n",
    "\n",
    "\n",
    "for y in range(ystart, yend):\n",
    "    predict = get_exp(a,b,y)\n",
    "    pdict = np.append(pdict, predict)\n",
    "\n",
    "    if y <= yend_true_data:\n",
    "        # use the real/true numbers.\n",
    "        pdict_scatter = np.append(pdict_scatter, ppm[y-ystart])\n",
    "        \n",
    "    else :\n",
    "        randft = np.random.normal(avg, std)\n",
    "        pdict_scatter = np.append(pdict_scatter, predict + randft)\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "# fig.add_traces(go.Scatter(x=year[:yend_true_data-ystart+1], y=pdict_scatter[:yend_true_data-ystart+1], mode = \"markers\", name = \"true data before 2021\"))\n",
    "# fig.add_traces(go.Scatter(x=year[yend_true_data-ystart+1:], y=pdict_scatter[yend_true_data-ystart+1:], mode = \"markers\", name = \"predict data after 2021\"))\n",
    "# fig.add_traces(go.Scatter(x=year, y=pdict, mode = \"lines\", name = \"trendline\"))\n",
    "\n",
    "fig.add_traces(go.Bar(x=year[:yend_true_data-ystart+1], y=pdict_scatter[:yend_true_data-ystart+1], name = \"true data before 2021\"))\n",
    "fig.add_traces(go.Bar(x=year[yend_true_data-ystart+1:], y=pdict_scatter[yend_true_data-ystart+1:], name = \"predict data after 2021\"))\n",
    "fig.add_traces(go.Scatter(x=year, y=pdict, name = \"trendline\"))\n",
    "\n",
    "\n",
    "fig.update_layout( \n",
    "        xaxis = dict(\n",
    "            title = \"Year\"\n",
    "        ),\n",
    "        yaxis = dict(\n",
    "            title = \"PPM\"\n",
    "        ),\n",
    "        title='PPM Increment with Years',\n",
    "        title_x=0.5,\n",
    "        # autosize=False,\n",
    "        width=2500,\n",
    "        height=1000,\n",
    "    )\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n",
    "# x_exact = np.linspace(1900, np.max(2100), 2100-1900+1)\n",
    "# y_exact = a * np.exp(b * x_exact)\n",
    "\n",
    "# fig = go.Figure()\n",
    "# fig.add_traces(go.Bar(x=x_exact, y=y_exact))\n",
    "# fig.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set a seed for the random number generator so we get the same random numbers each time\n",
    "np.random.seed(20210706)\n",
    "\n",
    "# Create fake x-data\n",
    "x = np.arange(10)\n",
    "# Create fake y-data\n",
    "a = 4.5\n",
    "b = 0.5\n",
    "y = a * np.exp(b * x)  # Use the second formulation from above\n",
    "y = y + np.random.normal(scale=np.sqrt(np.max(y)), size=len(x))  # Add noise\n",
    "\n",
    "#\n",
    "# Exact answer\n",
    "#\n",
    "x_exact = np.linspace(np.min(x), np.max(x), 100)\n",
    "y_exact = a * np.exp(b * x_exact)\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# curve_fit\n",
    "#\n",
    "# Fit the function a * np.exp(b * t) to x and y\n",
    "popt, pcov = curve_fit(lambda t, aa, bb: aa * np.exp(bb * t), x, y)\n",
    "# Extract the optimised parameters\n",
    "a = popt[0]\n",
    "b = popt[1]\n",
    "x_fitted_curve_fit = np.linspace(np.min(x), np.max(x), 100)\n",
    "y_fitted_curve_fit = a * np.exp(b * x_fitted_curve_fit)\n",
    "\n",
    "# Plot\n",
    "ax = plt.axes()\n",
    "ax.scatter(x, y, label='Raw data')\n",
    "ax.plot(x_exact, y_exact, 'k--', label='Exact answer')\n",
    "\n",
    "ax.plot(x_fitted_curve_fit, y_fitted_curve_fit, 'b', label=r'curve\\_fit')\n",
    "ax.set_title('Comparing the methods of fitting an exponential function')\n",
    "ax.set_ylabel('y-Values')\n",
    "ax.set_ylim(0, 450)\n",
    "ax.set_xlabel('x-Values')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 将包导入\n",
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "from  tensorflow.examples.tutorials.mnist  import  input_data\n",
    "import matplotlib as plt \n",
    "\n",
    "\n",
    "# 读取 moist 数据集\n",
    "mnist = input_data.read_data_sets('data', one_hot = True)\n",
    "\n",
    "# 设置参数\n",
    "num_classes = 10 # 要分成 10 类 \n",
    "input_size = 784 # 因为 moist的数据集每张图片有 28 ＊ 28 * 1个像素点\n",
    "training_iterations = 10000 # 训练迭代次数\n",
    "batch_size = 64 # 分批训练 一次取64个 batch 进行训练 (batch 应该尽量取大一点)\n",
    "\n",
    "\n",
    "#使用 placeholder 进行占位 None 表示第一维度大小任意\n",
    "X = tf.placeholder (tf.float32, shape = [None, input_size])\n",
    "Y = tf.placeholder (tf.float32, shape = [None, num_classes])\n",
    "\n",
    "# 使用 高维线性边界，假设边界参数\n",
    "W = tf.Variable (tf.random_normal ([input_size,num_classes], stddev = 0.1)) \n",
    "b = tf.Variable (tf.constant (0.1), [num_classes])\n",
    "\n",
    "# 计算预测值\n",
    "y_pred = tf.nn.softmax (tf.matmul (X,W) + b)\n",
    "\n",
    "# 搭建计算图 \n",
    "loss = tf.reduce_mean (tf.square (Y - y_pred))\n",
    "# loss 使用均方误差\n",
    "opt = tf.train.GradientDescentOptimizer (0.05).minimize (loss)\n",
    "# 使用梯度下降的方法最小化误差 0.05 是学习率\n",
    "init = tf.global_variables_initializer ()\n",
    "correct_prediction = tf.equal (tf.argmax (Y,1), tf.argmax (y_pred,1)) # 计算正确的个数 argmax 函数第一维表示 数据集 1 表示按照行 0 表示按照列 如果没有的话 表示整体求最大值 返回最大值所在的下标向量，然后 equal 对两个向量进行比较 相同得到1 不同得到0 \n",
    "accuracy = tf.reduce_mean (tf.cast (correct_prediction, 'float')) \n",
    "# 对上面得到的正确率取平均\n",
    "\n",
    "# 进行迭代运算\n",
    "sess = tf.Session ()\n",
    "sess.run (init)\n",
    "for i in range (training_iterations) :\n",
    "    batch = mnist.train.next_batch (batch_size) # 每次取出 64 个 数据进行训练\n",
    "    batch_input = batch[0] # 取出数据的第一维就是 输入的图像\n",
    "    batch_labels = batch[1] # 取出第二维 就是 它的 label 值 \n",
    "    training_loss = sess.run ([opt, loss], feed_dict = {X: batch_input, Y: batch_labels})\n",
    "    # 计算当前的损失值\n",
    "    if i % 1000 == 0 :\n",
    "        train_accuracy = accuracy.eval (session = sess, feed_dict = {X: batch_input,Y: batch_labels})\n",
    "        print (\"step : %d, training accuracy = %g \" % (i, train_accuracy)) # 打印正确率\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.markers as mks\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "\n",
    "\n",
    "class LogisticRegressionClass(object):\n",
    "    def __init__(self, dataX, dataY, testX, testY, learningRate, loopNum):\n",
    "        # X为输入的矩阵，一行代表一份数据，行数代表样本的数量，列数代表样本的维数\n",
    "        # Y为对应的结果值\n",
    "        # learningRate表示学习率\n",
    "        # loopNum表示训练的次数\n",
    "        self.trainX = dataX\n",
    "        self.trainY = dataY\n",
    "        self.learningRate = learningRate\n",
    "        self.loopNum = loopNum\n",
    "        self.Y_Train = np.array([self.trainY]).T  # 转化为列向量\n",
    "        self.X_Train = np.column_stack((dataX, np.repeat(1, dataX.shape[0])))  # 扩充矩阵一列全1，变成广义矩阵，作用是与偏置项进行乘积\n",
    "        self.parameter = np.array([np.ones(self.X_Train.shape[1])]).T  # 最后一位为偏置项\n",
    "        self.testX = testX\n",
    "        self.testY = testY\n",
    "        self.Y_Test = np.array([self.testY]).T\n",
    "        self.X_Test = np.column_stack((testX, np.repeat(1, testX.shape[0])))\n",
    "        self.WTX = None  # W为参数，T为转置，X为数据\n",
    "        self.error = None  # 误差\n",
    "        self.derivative = None  # 梯度值\n",
    "\n",
    "    def GradientDecent(self):\n",
    "        # 梯度下降法\n",
    "        # 梯度的计算值是根据最大似然估计得出的结论\n",
    "        for i in range(self.loopNum):\n",
    "            self.WTX = np.dot(self.X_Train, self.parameter)\n",
    "            Sig_Wtx = SigmoidFunction(self.WTX)  # (398, 1)\n",
    "            self.error = Sig_Wtx - self.Y_Train\n",
    "            self.derivative = np.dot(self.X_Train.T, self.error)\n",
    "            self.parameter -= self.learningRate * self.derivative\n",
    "            self.show_training()\n",
    "            plt.pause(0.03)\n",
    "        plt.show()\n",
    "\n",
    "    def StochasticGradientDecent(self):\n",
    "        # 随机梯度下降法\n",
    "        count = 0\n",
    "        for loop in range(self.loopNum):\n",
    "            List_NoRepeat_Random = random.sample(range(0, self.X_Train.shape[0]), self.X_Train.shape[0])\n",
    "            for index in List_NoRepeat_Random:\n",
    "                self.WTX = np.dot(self.X_Train[index], self.parameter)\n",
    "                Sig_Wtx = SigmoidFunction(self.WTX)\n",
    "                self.error = np.matrix(self.Y_Train[index] - Sig_Wtx)\n",
    "                self.derivative = np.dot(np.matrix(self.X_Train[index]).T, self.error)\n",
    "                self.parameter += self.learningRate * self.derivative\n",
    "                # 每五十次训练进行一次输出结果的显示\n",
    "                count += 1\n",
    "                if count % 50 == 0:\n",
    "                    self.show_training()\n",
    "                    plt.pause(0.03)\n",
    "        plt.show()\n",
    "\n",
    "    def Train_acc(self):\n",
    "        # 训练集的正确率计算\n",
    "        predict_y = np.dot(self.X_Train, self.parameter)\n",
    "        predict_y = SigmoidFunction(predict_y)\n",
    "        predict_y = np.where(predict_y > 0.5, 1, 0)\n",
    "        predict_y = predict_y ^ self.Y_Train\n",
    "        acc = (self.X_Train.shape[0] - np.sum(predict_y)) / self.X_Train.shape[0]\n",
    "        print('Train_acc= {:.2%}'.format(acc))\n",
    "\n",
    "    def Test_acc(self):\n",
    "        # 测试集的正确率计算\n",
    "        predict_y = np.dot(self.X_Test, self.parameter)\n",
    "        predict_y = SigmoidFunction(predict_y)\n",
    "        predict_y = np.where(predict_y > 0.5, 1, 0)\n",
    "        predict_y = predict_y ^ self.Y_Test\n",
    "        acc = (self.testX.shape[0] - np.sum(predict_y)) / self.testX.shape[0]\n",
    "        print('Test_acc= {:.2%}'.format(acc))\n",
    "\n",
    "    def show_training(self):\n",
    "        # 对训练出的参数进行输出显示\n",
    "        Param = Para_manager(self.parameter)\n",
    "        self.train_show(Param)\n",
    "\n",
    "    def test_show(self, Param):\n",
    "        # 验证集输出显示\n",
    "        X_index = np.column_stack((self.testX[:, 0], np.repeat(1, self.testX.shape[0])))\n",
    "        pre = np.dot(X_index, Param)\n",
    "        plotMatrixPoint(self.testX, self.testY, pre)\n",
    "\n",
    "    def train_show(self, Param):\n",
    "        # 训练集输出显示\n",
    "        X_index = np.column_stack((self.trainX[:, 0], np.repeat(1, self.trainX.shape[0])))\n",
    "        pre = np.dot(X_index, Param)\n",
    "        plotMatrixPoint(self.trainX, self.trainY, pre)\n",
    "\n",
    "\n",
    "def SigmoidFunction(X):\n",
    "    return 1. / (1. + np.exp(-X))\n",
    "\n",
    "\n",
    "def Para_manager(Param):\n",
    "    # 把三维的参数转化为能够在plt图上显示的y=kx+b的格式，返回k与b\n",
    "    Param[0] /= -Param[1]\n",
    "    Param[2] /= -Param[1]\n",
    "    Param = np.array([Param[0], Param[2]])\n",
    "    return Param\n",
    "\n",
    "\n",
    "def DIY_Scatter(x, y, ax=None, m=None, **kw):\n",
    "    # 自定义参数设计\n",
    "    if not ax:\n",
    "        ax = plt.gca()\n",
    "    sc = ax.scatter(x, y, **kw)\n",
    "    if m is not None and len(m) == len(x):\n",
    "        paths = []\n",
    "        for marker in m:\n",
    "            if isinstance(marker, mks.MarkerStyle):\n",
    "                marker_obj = marker\n",
    "            else:\n",
    "                marker_obj = mks.MarkerStyle(marker)\n",
    "            path = marker_obj.get_path().transformed(\n",
    "                marker_obj.get_transform())\n",
    "            paths.append(path)\n",
    "        sc.set_paths(paths)\n",
    "    return sc\n",
    "\n",
    "\n",
    "def plotMatrixPoint(dataX, dataY, predict):\n",
    "    plt.clf()\n",
    "    x = dataX[:, 0]\n",
    "    y = dataX[:, 1]\n",
    "    map_size = {0: 30, 1: 30}  # 大小\n",
    "    size = list(map(lambda index: map_size[index], dataY))\n",
    "    map_color = {0: 'r', 1: 'g'}  # 颜色\n",
    "    color = list(map(lambda index: map_color[index], dataY))\n",
    "    map_marker = {0: 'o', 1: 's'}  # 形状\n",
    "    markers = list(map(lambda index: map_marker[index], dataY))\n",
    "    DIY_Scatter(x, y, s=size, c=color, m=markers)  # scatter函数只支持array类型数据\n",
    "    plt.axis([1.25 * min(x), 1.25 * max(x), 1.25 * min(y), 1.25 * max(y)])\n",
    "    plt.plot(dataX[:, 0], predict, color='red', linewidth=1)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    breast_cancer = datasets.load_breast_cancer()\n",
    "    data_X = breast_cancer.data\n",
    "    data_Y = breast_cancer.target\n",
    "\n",
    "    data_X = data_X[:, 0:2]  # 取了原数据集中的两列，作为后续能够显示的数据集基础\n",
    "\n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(data_X, data_Y, test_size=0.3, random_state=123)\n",
    "    # 对训练集测试集进行正则化\n",
    "    Scaler = StandardScaler().fit(train_X)\n",
    "    train_X = Scaler.transform(train_X)\n",
    "    test_X = Scaler.transform(test_X)\n",
    "\n",
    "    LogisticX = LogisticRegressionClass(train_X, train_Y, test_X, test_Y, 0.01, 100)\n",
    "    # LogisticX.GradientDecent()\n",
    "    LogisticX.StochasticGradientDecent()\n",
    "    LogisticX.Test_acc()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def perdict(w,x): #根据权重和逻辑函数求解最新的预测值，x为单个数据\n",
    "    if len(w) != len(x):\n",
    "        print(\"w和x的维度不一致\")\n",
    "        return None\n",
    "    z=0\n",
    "    for index in range(len(w)):\n",
    "       z = z + w[index]*x[index]\n",
    "    y = (1+np.e**-(z))**-1\n",
    "    return y\n",
    "\n",
    "def upadteWeight(oldW, data, predict, label): #按照梯度下降的原则更新权重\n",
    "    offset = np.array([np.array(data[i]) * (label[i] - j) for i,j in enumerate(predict)])\n",
    "    offset = np.array([np.sum(offset[...,index]) for index in range(len(w))])/len(data)\n",
    "    newW = oldW + offset\n",
    "    return newW\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    data = [[1,0,1],[2,0,1],[3,0,1],[8,9,1],[9,9,1],[10,9,1]]\n",
    "    label = [1970, 1980, 1990, 2000, 2010, 2020,2030,2040,2050,2060]\n",
    "    w = [0,0,0]\n",
    "    while True:\n",
    "        predicts = [perdict(w,index) for index in data]\n",
    "        w=upadteWeight(w, data, predicts, label)\n",
    "        if sum(predicts[:3])<0.5 and sum(predicts[3:])>2: #设置更新退出条件，前三个的预测值足够第（代表类别为0），后三个预测足够高（类别为1）\n",
    "            break;\n",
    "    print(\"w:\", w)\n",
    "    print(\"predict:\", predicts)\n",
    "    print(perdict(w,[10,8,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import r2_score \n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "\n",
    "# 已有数据\n",
    "df = pd.read_excel('2022_HiMCM_Data-B-co2.xlsx',sheet_name=\"origin\")\n",
    "year = df['Year'].to_numpy()\n",
    "ppm = df['PPM'].to_numpy()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    data=load_breast_cancer() #加载数据集\n",
    "    X =data['data'] #数据\n",
    "    Y = data['target'] #标签\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.3,random_state=1) #划分测试集和训练集\n",
    "    l1 = LogisticRegression(penalty=\"l1\",C=0.5,solver=\"liblinear\") #配置逻辑回归，penalty为正则化，solver为求解w的方法\n",
    "    l1.fit(X_train,Y_train)\n",
    "    score =  l1.score(X_test,Y_test)\n",
    "    print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_excel('2022_HiMCM_Data-B.xlsx',sheet_name = 'Sheet4')\n",
    "X = dataset['Year'].values\n",
    "y = dataset['PPM'].values\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# sklearn 拟合输入输出一般都是二维数组，这里将一维转换为二维。\n",
    "X_train = np.array(X_train).reshape(-1, 1)\n",
    "X_test = np.array(X_test).reshape(-1, 1)\n",
    "# y_train = np.array(y_train).reshape(-1, 1)\n",
    "# y_test = np.array(y_test).reshape(-1, 1)\n",
    "\n",
    "# ppm = np.array(ppm).reshape(-1, 1)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "\n",
    "# Fitting Logistic Regression to the Training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "print(y_train)\n",
    "classifier.fit(X_train, y_train.astype('int'))\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "\n",
    "# Visualing the Training set results\n",
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = X_train, y_train\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                c = ListedColormap(('orange', 'blue'))(i), label = j)\n",
    "plt.title('Logistic Regression (Training set)')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Estimated Salary')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Visualising the Test set results\n",
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = X_test, y_test\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                c = ListedColormap(('orange', 'blue'))(i), label = j)\n",
    "plt.title('Logistic Regression (Test set)')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Estimated Salary')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CO2 Emission\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import r2_score \n",
    "\n",
    "df = pd.read_excel('CO2EMISSION.xlsx',sheet_name = 'Sheet1')\n",
    "df1 = pd.read_excel('CO2EMISSION.xlsx',sheet_name = 'Sheet2')\n",
    "\n",
    "# USA\n",
    "yearo = df['Year'].tolist()\n",
    "ppmo = df['Emission'].tolist()\n",
    "\n",
    "# China\n",
    "yearc = df1['Year'].tolist()\n",
    "ppmc = df1['Emission'].tolist()\n",
    "\n",
    "fig1 = go.Figure()\n",
    "fig1.add_traces(go.Scatter(x=yearo, y=ppmo, mode = \"markers+lines\", name = \"PPM\"))\n",
    "# fig.add_traces(go.Scatter(x=yeard, y=ppmd, mode = \"markers+lines\", name = \"predict_data\")\n",
    "\n",
    "fig1.update_layout( \n",
    "        xaxis = dict(\n",
    "            title = \"Year\"\n",
    "        ),\n",
    "        yaxis = dict(\n",
    "            title = \"CO2 Emission\"\n",
    "        ),\n",
    "        title='CO2 Emission in USA',\n",
    "        title_x=0.5,\n",
    "        # autosize=False,\n",
    "        width=1500,\n",
    "        height=800,\n",
    "    )\n",
    "\n",
    "fig2 = go.Figure()\n",
    "fig2.add_traces(go.Scatter(x=yearc, y=ppmc, mode = \"markers+lines\", name = \"PPM\"))\n",
    "# fig.add_traces(go.Scatter(x=yeard, y=ppmd, mode = \"markers+lines\", name = \"predict_data\")\n",
    "\n",
    "fig2.update_layout( \n",
    "        xaxis = dict(\n",
    "            title = \"Year\"\n",
    "        ),\n",
    "        yaxis = dict(\n",
    "            title = \"CO2 Emission\"\n",
    "        ),\n",
    "        title='CO2 Emission in China',\n",
    "        title_x=0.5,\n",
    "        # autosize=False,\n",
    "        width=1500,\n",
    "        height=800,\n",
    "    )\n",
    "\n",
    "fig1.show()\n",
    "fig2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Population\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import r2_score \n",
    "\n",
    "df = pd.read_excel('CO2EMISSION.xlsx',sheet_name = 'Sheet4')\n",
    "df1 = pd.read_excel('CO2EMISSION.xlsx',sheet_name = 'Sheet3')\n",
    "\n",
    "# USA\n",
    "yearo = df['Year'].tolist()\n",
    "ppmo = df['Population'].tolist()\n",
    "\n",
    "# China\n",
    "yearc = df1['Year'].tolist()\n",
    "ppmc = df1['Population'].tolist()\n",
    "\n",
    "fig1 = go.Figure()\n",
    "fig1.add_traces(go.Scatter(x=yearo, y=ppmo, mode = \"markers+lines\", name = \"PPM\"))\n",
    "# fig.add_traces(go.Scatter(x=yeard, y=ppmd, mode = \"markers+lines\", name = \"predict_data\")\n",
    "\n",
    "fig1.update_layout( \n",
    "        xaxis = dict(\n",
    "            title = \"Year\"\n",
    "        ),\n",
    "        yaxis = dict(\n",
    "            title = \"Population\"\n",
    "        ),\n",
    "        title='Population Growth in USA',\n",
    "        title_x=0.5,\n",
    "        # autosize=False,\n",
    "        width=1500,\n",
    "        height=800,\n",
    "    )\n",
    "\n",
    "fig2 = go.Figure()\n",
    "fig2.add_traces(go.Scatter(x=yearc, y=ppmc, mode = \"markers+lines\", name = \"PPM\"))\n",
    "# fig.add_traces(go.Scatter(x=yeard, y=ppmd, mode = \"markers+lines\", name = \"predict_data\")\n",
    "\n",
    "fig2.update_layout( \n",
    "        xaxis = dict(\n",
    "            title = \"Year\"\n",
    "        ),\n",
    "        yaxis = dict(\n",
    "            title = \"Population\"\n",
    "        ),\n",
    "        title='Population Growth in China',\n",
    "        title_x=0.5,\n",
    "        # autosize=False,\n",
    "        width=1500,\n",
    "        height=800,\n",
    "    )\n",
    "\n",
    "fig1.show()\n",
    "fig2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDP\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import r2_score \n",
    "\n",
    "df = pd.read_excel('CO2EMISSION.xlsx',sheet_name = 'Sheet4')\n",
    "df1 = pd.read_excel('CO2EMISSION.xlsx',sheet_name = 'Sheet3')\n",
    "\n",
    "# USA\n",
    "yearo = df['Year'].tolist()\n",
    "ppmo = df['Population'].tolist()\n",
    "\n",
    "# China\n",
    "yearc = df1['Year'].tolist()\n",
    "ppmc = df1['Population'].tolist()\n",
    "\n",
    "fig1 = go.Figure()\n",
    "fig1.add_traces(go.Scatter(x=yearo, y=ppmo, mode = \"markers+lines\", name = \"PPM\"))\n",
    "# fig.add_traces(go.Scatter(x=yeard, y=ppmd, mode = \"markers+lines\", name = \"predict_data\")\n",
    "\n",
    "fig1.update_layout( \n",
    "        xaxis = dict(\n",
    "            title = \"Year\"\n",
    "        ),\n",
    "        yaxis = dict(\n",
    "            title = \"Population\"\n",
    "        ),\n",
    "        title='Population Growth in USA',\n",
    "        title_x=0.5,\n",
    "        # autosize=False,\n",
    "        width=1500,\n",
    "        height=800,\n",
    "    )\n",
    "\n",
    "fig2 = go.Figure()\n",
    "fig2.add_traces(go.Scatter(x=yearc, y=ppmc, mode = \"markers+lines\", name = \"PPM\"))\n",
    "# fig.add_traces(go.Scatter(x=yeard, y=ppmd, mode = \"markers+lines\", name = \"predict_data\")\n",
    "\n",
    "fig2.update_layout( \n",
    "        xaxis = dict(\n",
    "            title = \"Year\"\n",
    "        ),\n",
    "        yaxis = dict(\n",
    "            title = \"Population\"\n",
    "        ),\n",
    "        title='Population Growth in China',\n",
    "        title_x=0.5,\n",
    "        # autosize=False,\n",
    "        width=1500,\n",
    "        height=800,\n",
    "    )\n",
    "\n",
    "fig1.show()\n",
    "fig2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDP\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import r2_score \n",
    "\n",
    "df = pd.read_excel('2022_HiMCM_Data-B.xlsx',sheet_name = 'CO2 Data Set 1')\n",
    "df1 = pd.read_excel('2022_HiMCM_Data-B.xlsx',sheet_name = 'Sheet4')\n",
    "\n",
    "# Original\n",
    "yearo = df['Year'].tolist()\n",
    "ppmo = df['PPM'].tolist()\n",
    "\n",
    "# After\n",
    "yearc = df1['Year'].tolist()\n",
    "ppmc = df1['PPM'].tolist()\n",
    "\n",
    "fig1 = go.Figure()\n",
    "fig1.add_traces(go.Scatter(x=yearo, y=ppmo, mode = \"markers\", name = \"PPM\"))\n",
    "# fig.add_traces(go.Scatter(x=yeard, y=ppmd, mode = \"markers+lines\", name = \"predict_data\"))\n",
    "\n",
    "fig1.update_layout( \n",
    "        xaxis = dict(\n",
    "            title = \"Year\"\n",
    "        ),\n",
    "        yaxis = dict(\n",
    "            title = \"PPM\"\n",
    "        ),\n",
    "        title='CO2 in Atmosphere',\n",
    "        title_x=0.5,\n",
    "        # autosize=False,\n",
    "        width=1500,\n",
    "        height=800,\n",
    "    )\n",
    "\n",
    "fig2 = go.Figure()\n",
    "fig2.add_traces(go.Scatter(x=yearc, y=ppmc, mode = \"markers\", name = \"PPM\"))\n",
    "# fig.add_traces(go.Scatter(x=yeard, y=ppmd, mode = \"markers+lines\", name = \"predict_data\")\n",
    "\n",
    "fig2.update_layout( \n",
    "        xaxis = dict(\n",
    "            title = \"Year\"\n",
    "        ),\n",
    "        yaxis = dict(\n",
    "            title = \"PPM\"\n",
    "        ),\n",
    "        title='CO2 in Atmosphere between 1980-2021',\n",
    "        title_x=0.5,\n",
    "        # autosize=False,\n",
    "        width=1500,\n",
    "        height=800,\n",
    "    )\n",
    "\n",
    "fig1.show()\n",
    "fig2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change in ppm\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import r2_score \n",
    "\n",
    "df = pd.read_excel('CO2EMISSION.xlsx',sheet_name = 'Sheet5')\n",
    "\n",
    "yearo = df['Year'].tolist()\n",
    "ppmo = df['Change in PPM'].tolist()\n",
    "\n",
    "fig1 = go.Figure()\n",
    "obj = go.Table(header = dict(values=[\"Year\", \"Change in PPM\"]),\n",
    "                cells = dict(values=[yearo, ppmo]))\n",
    "# fig.add_traces(go.Scatter(x=yeard, y=ppmd, mode = \"markers+lines\", name = \"predict_data\")\n",
    "fig1.add_trace(obj)\n",
    "fig1.show()\n",
    "\n",
    "# fig1.update_layout( \n",
    "#         xaxis = dict(\n",
    "#             title = \"Year\"\n",
    "#         ),\n",
    "#         yaxis = dict(\n",
    "#             title = \"Population\"\n",
    "#         ),\n",
    "#         title='Population Growth in USA',\n",
    "#         title_x=0.5,\n",
    "#         # autosize=False,\n",
    "#         width=1500,\n",
    "#         height=800,\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings                                  # do not disturbe mode\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load packages\n",
    "import numpy as np                               # vectors and matrices\n",
    "import pandas as pd                              # tables and data manipulations\n",
    "import matplotlib.pyplot as plt                  # plots\n",
    "import seaborn as sns                            # more plots\n",
    "\n",
    "from dateutil.relativedelta import relativedelta # working with dates with style\n",
    "from scipy.optimize import minimize              # for function minimization\n",
    "\n",
    "import statsmodels.formula.api as smf            # statistics and econometrics\n",
    "import statsmodels.tsa.api as smt\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as scs\n",
    "\n",
    "from itertools import product                    # some useful functions\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "# Importing everything from forecasting quality metrics\n",
    "from sklearn.metrics import r2_score, median_absolute_error, mean_absolute_error\n",
    "from sklearn.metrics import median_absolute_error, mean_squared_error, mean_squared_log_error\n",
    "\n",
    "# MAPE 平均绝对误差\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    \n",
    "def tsplot(y, lags=None, figsize=(12, 7), style='bmh'):\n",
    "    # \"\"\"\n",
    "    #     Plot time series, its ACF and PACF, calculate Dickey–Fuller test\n",
    "        \n",
    "    #     y - timeseries\n",
    "    #     lags - how many lags to include in ACF, PACF calculation\n",
    "    # \"\"\"\n",
    "    \n",
    "    if not isinstance(y, pd.Series):\n",
    "        y = pd.Series(y)\n",
    "        \n",
    "    with plt.style.context(style):    \n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        layout = (2, 2)\n",
    "        ts_ax = plt.subplot2grid(layout, (0, 0), colspan=2)\n",
    "        acf_ax = plt.subplot2grid(layout, (1, 0))\n",
    "        pacf_ax = plt.subplot2grid(layout, (1, 1))\n",
    "        \n",
    "        y.plot(ax=ts_ax)\n",
    "        p_value = sm.tsa.stattools.adfuller(y)[1]\n",
    "        ts_ax.set_title('Time Series Analysis Plots\\n Dickey-Fuller: p={0:.5f}'.format(p_value))\n",
    "        smt.graphics.plot_acf(y, lags=lags, ax=acf_ax)\n",
    "        smt.graphics.plot_pacf(y, lags=lags, ax=pacf_ax)\n",
    "        plt.tight_layout()\n",
    "\n",
    "\n",
    "ads = pd.read_csv('2022_HiMCM_Data-B.xlsx'',index_col=['Time'], parse_dates=['Time'])\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "plt.plot(ads.Ads)\n",
    "plt.title('Ads watched (hourly data)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "tsplot(ads.Ads, lags=60)\n",
    "\n",
    "# The seasonal difference\n",
    "ads_diff = ads.Ads - ads.Ads.shift(24)\n",
    "tsplot(ads_diff[24:], lags=60)\n",
    "\n",
    "ads_diff = ads_diff - ads_diff.shift(1)\n",
    "tsplot(ads_diff[24+1:], lags=60)\n",
    "\n",
    "# setting initial values and some bounds for them\n",
    "ps = range(2, 5)\n",
    "d=1 \n",
    "qs = range(2, 5)\n",
    "Ps = range(0, 2)\n",
    "D=1 \n",
    "Qs = range(0, 2)\n",
    "s = 24 # season length is still 24\n",
    "\n",
    "# creating list with all the possible combinations of parameters\n",
    "parameters = product(ps, qs, Ps, Qs)\n",
    "parameters_list = list(parameters)\n",
    "len(parameters_list)\n",
    "\n",
    "def optimizeSARIMA(y, parameters_list, d, D, s):\n",
    "    # \"\"\"Return dataframe with parameters and corresponding AIC\n",
    "        \n",
    "    #     y - time series\n",
    "    #     parameters_list - list with (p, q, P, Q) tuples\n",
    "    #     d - integration order in ARIMA model\n",
    "    #     D - seasonal integration order \n",
    "    #     s - length of season\n",
    "    # \"\"\"\n",
    "    \n",
    "    results = []\n",
    "    best_aic = float(\"inf\")\n",
    "\n",
    "    for param in tqdm_notebook(parameters_list):\n",
    "        # we need try-except because on some combinations model fails to converge\n",
    "        try:\n",
    "            model=sm.tsa.statespace.SARIMAX(y, order=(param[0], d, param[1]), \n",
    "                                            seasonal_order=(param[2], D, param[3], s)).fit(disp=-1)\n",
    "        except Exception:\n",
    "            continue\n",
    "        aic = model.aic\n",
    "        # saving best model, AIC and parameters\n",
    "        if aic < best_aic:\n",
    "            best_model = model\n",
    "            best_aic = aic\n",
    "            best_param = param\n",
    "        results.append([param, model.aic])\n",
    "\n",
    "    result_table = pd.DataFrame(results)\n",
    "    result_table.columns = ['parameters', 'aic']\n",
    "    # sorting in ascending order, the lower AIC is - the better\n",
    "    result_table = result_table.sort_values(by='aic', ascending=True).reset_index(drop=True)\n",
    "\n",
    "    return result_table\n",
    "\n",
    "%%time\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "result_table = optimizeSARIMA(ads.Ads, parameters_list, d, D, s)\n",
    "\n",
    "result_table.head()\n",
    "\n",
    "# set the parameters that give the lowest AIC\n",
    "p, q, P, Q = result_table.parameters[0]\n",
    "\n",
    "best_model=sm.tsa.statespace.SARIMAX(ads.Ads, order=(p, d, q), \n",
    "                                        seasonal_order=(P, D, Q, s)).fit(disp=-1)\n",
    "print(best_model.summary())\n",
    "\n",
    "tsplot(best_model.resid[24+1:], lags=60)\n",
    "\n",
    "def plotSARIMA(series, model, n_steps):\n",
    "    # \"\"\"Plots model vs predicted values\n",
    "        \n",
    "    #     series - dataset with timeseries\n",
    "    #     model - fitted SARIMA model\n",
    "    #     n_steps - number of steps to predict in the future    \n",
    "    # \"\"\"\n",
    "    \n",
    "    # adding model values\n",
    "    data = series.copy()\n",
    "    data.columns = ['actual']\n",
    "    data['sarima_model'] = model.fittedvalues\n",
    "    # making a shift on s+d steps, because these values were unobserved by the model\n",
    "    # due to the differentiating\n",
    "    data['sarima_model'][:s+d] = np.NaN\n",
    "    \n",
    "    # forecasting on n_steps forward \n",
    "    forecast = model.predict(start = data.shape[0], end = data.shape[0]+n_steps)\n",
    "    forecast = data.sarima_model.append(forecast)\n",
    "    # calculate error, again having shifted on s+d steps from the beginning\n",
    "    error = mean_absolute_percentage_error(data['actual'][s+d:], data['sarima_model'][s+d:])\n",
    "\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.title(\"Mean Absolute Percentage Error: {0:.2f}%\".format(error))\n",
    "    plt.plot(forecast, color='r', label=\"model\")\n",
    "    plt.axvspan(data.index[-1], forecast.index[-1], alpha=0.5, color='lightgrey')\n",
    "    plt.plot(data.actual, label=\"actual\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "plotSARIMA(ads, best_model, 50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dbd1ced04e1a75aa211a3cad66fcd043bbd2f3f4264b33dd4cf9d79041e2bd71"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
